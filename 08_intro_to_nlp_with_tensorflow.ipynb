{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "263be215-0b4c-4ae6-b29f-9b647f15d871",
      "metadata": {
        "id": "263be215-0b4c-4ae6-b29f-9b647f15d871"
      },
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP is focused on deriving information from natural language (text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence (seq2seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6757e258-3cb5-42bc-9382-12474f5462db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6757e258-3cb5-42bc-9382-12474f5462db",
        "outputId": "aac63f97-c3c3-4db0-8761-bd26402b63f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-11f57e92-413b-d759-1823-77e1baa3a39d)\n"
          ]
        }
      ],
      "source": [
        "## Check for GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download helper funciton python script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC-ZgvbbiyAn",
        "outputId": "a5159a8e-6928-4e05-fbb8-440a410fcf4d"
      },
      "id": "RC-ZgvbbiyAn",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-27 17:17:32--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-27 17:17:32 (80.0 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e85ad1bb-15e4-4b24-ab7f-9e948ca497ef",
      "metadata": {
        "id": "e85ad1bb-15e4-4b24-ab7f-9e948ca497ef"
      },
      "outputs": [],
      "source": [
        "# Import functions from helper_functions.py\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c25bb2-cd4e-4e7b-95c5-9ee3bf92ca93",
      "metadata": {
        "id": "99c25bb2-cd4e-4e7b-95c5-9ee3bf92ca93"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "I am using the the [Kaggle's Introduction to NLP dataset](https://www.kaggle.com/competitions/nlp-getting-started), a set of tweets for binary classifications of disasters.\n",
        "\n",
        "I will be downloading the dataset from [my course github here](https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2c03dc5d-c110-439d-812a-8a28ee51de14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c03dc5d-c110-439d-812a-8a28ee51de14",
        "outputId": "e3986815-bd71-47ff-bc7a-fd2a6b6aab2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-27 17:17:40--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.197.128, 74.125.135.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-01-27 17:17:40 (40.3 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# downloads the dataset from google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "14e7c453-267c-4dcf-8a1e-76fca93cc335",
      "metadata": {
        "id": "14e7c453-267c-4dcf-8a1e-76fca93cc335"
      },
      "outputs": [],
      "source": [
        "# Unzip the data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffae5ed1-b8e6-49c9-88e3-713b39372613",
      "metadata": {
        "id": "ffae5ed1-b8e6-49c9-88e3-713b39372613"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "Need to visualize our text dataset using Python's Pandas.\n",
        "\n",
        "**NOTE**: A Pandas dataframe can only be the same size as RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ca4d0576-fb7a-4dff-a363-c2c8ec0f9a8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ca4d0576-fb7a-4dff-a363-c2c8ec0f9a8a",
        "outputId": "9e45733f-df43-4202-a728-6c4344355a5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13fa52e5-fc85-4f99-9b24-a8662a77b172\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13fa52e5-fc85-4f99-9b24-a8662a77b172')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13fa52e5-fc85-4f99-9b24-a8662a77b172 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13fa52e5-fc85-4f99-9b24-a8662a77b172');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c65799bf-2de3-4e8f-a85f-82c4b64c2bd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c65799bf-2de3-4e8f-a85f-82c4b64c2bd4",
        "outputId": "b42b71aa-114d-4355-a6da-aed3ba121a20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8c65f1c-1f0d-449d-832d-5d813a4eaac5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8c65f1c-1f0d-449d-832d-5d813a4eaac5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8c65f1c-1f0d-449d-832d-5d813a4eaac5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8c65f1c-1f0d-449d-832d-5d813a4eaac5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f33c2873-c5c8-4be7-9e64-ee2255728a57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f33c2873-c5c8-4be7-9e64-ee2255728a57",
        "outputId": "a42b89c6-57d7-40bf-e679-cf242fb58507"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f32b649-9e32-462b-967b-1a56897c1c10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f32b649-9e32-462b-967b-1a56897c1c10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f32b649-9e32-462b-967b-1a56897c1c10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f32b649-9e32-462b-967b-1a56897c1c10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# check out test dataframe \n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "48be250d-f11a-4484-a4be-dec53ec3578e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48be250d-f11a-4484-a4be-dec53ec3578e",
        "outputId": "182b9ccb-3154-4323-e0f3-0f08bf48c6dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# quantity of examples of each class\n",
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81e9ad90-513f-4ca7-8f8d-ac9b48acf3f0",
      "metadata": {
        "id": "81e9ad90-513f-4ca7-8f8d-ac9b48acf3f0"
      },
      "source": [
        "> This is fairly balanced, no balancing required. Otherwise look up imbalanced classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8780db46-ba31-47e5-979f-55ae08c9f9b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8780db46-ba31-47e5-979f-55ae08c9f9b7",
        "outputId": "06a80c72-11ec-41d5-e29e-d3f4acddbfa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Total samples\n",
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a9dd16d9-f041-471f-a055-c782c8d97df7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9dd16d9-f041-471f-a055-c782c8d97df7",
        "outputId": "9b5a29ce-9406-4ca5-891a-7f8120866fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not a real disaster)\n",
            "Text:\n",
            "SEAN END CAREER sG Blizzard vs KNOCKOUT ... http://t.co/nyv51681uE\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not a real disaster)\n",
            "Text:\n",
            "I liked a @YouTube video http://t.co/YdgiUYdqgb Mini Pony packs a punch. Live report from the Salem County Fair on CBS3 Eyewitness\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not a real disaster)\n",
            "Text:\n",
            "@tareksocal I think a lot of celebrities have to treat ppl as if they could harm them\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Service on the Green Line has resumed after an earlier derailment near Garfield with residual delays.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not a real disaster)\n",
            "Text:\n",
            "Bright &amp; BLAZING Fireman Birthday Party http://t.co/9rFo9GY3nE #Weddings\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Visualize random training samples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df) - 5) # create random indexes not higher than total samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index: random_index + 5].itertuples():\n",
        "    _, text, target = row\n",
        "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not a real disaster)\")\n",
        "    print(f\"Text:\\n{text}\\n\")\n",
        "    print(\"---\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "343de767-e15f-4059-a867-6ae1a48f4d3a",
      "metadata": {
        "id": "343de767-e15f-4059-a867-6ae1a48f4d3a"
      },
      "source": [
        "### Split data into training and validation data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "93d088c6-6111-4901-aa47-69cb415ca4ce",
      "metadata": {
        "id": "93d088c6-6111-4901-aa47-69cb415ca4ce"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0546244e-aec7-45b7-aeb3-22d613e7b73b",
      "metadata": {
        "id": "0546244e-aec7-45b7-aeb3-22d613e7b73b"
      },
      "outputs": [],
      "source": [
        "# use train_test_split to split training data into train and validation splits\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                           train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                           test_size=0.1,\n",
        "                                                                           random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a0ee6c3c-402c-4f57-abc0-f5bb6adcd5a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ee6c3c-402c-4f57-abc0-f5bb6adcd5a0",
        "outputId": "11e55035-66fa-4fda-a11e-686f974080a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# check the lengths of each split\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a10d97e3-2e8a-445f-b2ac-7f9ec88a3190",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a10d97e3-2e8a-445f-b2ac-7f9ec88a3190",
        "outputId": "ce3cbb16-f4a4-495f-82f4-1f71af7cd6a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7c57882-e4a5-4f0c-9418-13b492ec9980",
      "metadata": {
        "id": "c7c57882-e4a5-4f0c-9418-13b492ec9980"
      },
      "source": [
        "## converting text into numbers\n",
        "\n",
        "There are multiple ways to convert text to numbers:\n",
        "* Tokenization - direct mapping of token (word or character) to a number\n",
        "* Embedding - Creates a vector for each word of arbitrary length (128, 256, 512, etc) and creates a matrix to support showing relationships. The embedding matrix acts as a layer that can be trained as more text is analyzed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6b8324-8f91-41a4-8514-80abc5f2cf74",
      "metadata": {
        "id": "ad6b8324-8f91-41a4-8514-80abc5f2cf74"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1eb90fcb-e031-4be1-ae85-a822d17377da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eb90fcb-e031-4be1-ae85-a822d17377da",
        "outputId": "4a4dd322-90d4-4a5f-e500-cf939bce7102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Look at the data\n",
        "train_sentences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "84e583b3-8e96-4834-a435-5b5573a1afa0",
      "metadata": {
        "id": "84e583b3-8e96-4834-a435-5b5573a1afa0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in our vocabulary (automatically add <OOV>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # lowercase and removes punctuation\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, # create groups of n-words\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # pads each sequence to be the same length as the longest sequence is\n",
        "                                    pad_to_max_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c1798b8f-1795-410f-88a8-afad8414abe6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1798b8f-1795-410f-88a8-afad8414abe6",
        "outputId": "8c61a1aa-6c85-40fa-ac86-3de8c2b04613"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# find the average number of tokens (words) in the training tweets\n",
        "total_words = sum([len(i.split()) for i in train_sentences])\n",
        "\n",
        "# this produces a float so we round to get an int\n",
        "average_words = round(total_words / len(train_sentences))\n",
        "\n",
        "average_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8c940807-20f2-41a5-a787-e58be1319a17",
      "metadata": {
        "id": "8c940807-20f2-41a5-a787-e58be1319a17"
      },
      "outputs": [],
      "source": [
        "# set up text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be, condenses sentences to this max length\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length, # max vocab of 10k words\n",
        "                                   output_mode=\"int\",\n",
        "                                   output_sequence_length=max_length) # truncate or pad to match the maximum sequence length of 15 in our case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1378f456-5838-41e1-acac-f5d241375a3c",
      "metadata": {
        "id": "1378f456-5838-41e1-acac-f5d241375a3c"
      },
      "outputs": [],
      "source": [
        "# Fit the text\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6ed1debb-1ec4-4097-a4d8-b0730fd96fa6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ed1debb-1ec4-4097-a4d8-b0730fd96fa6",
        "outputId": "6d8507ac-c0ae-4d20-9bea-038e1f7aac4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9043e50e-aadf-4625-a954-6a8e169c2a93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9043e50e-aadf-4625-a954-6a8e169c2a93",
        "outputId": "f5623c06-5192-4dd6-a8a5-6784698552bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " Amazon Deal - wait or buy? http://t.co/0T8VqKEArI\n",
            "\n",
            " Vectorized Version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1329,  711,  637,   53, 1151,    1,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# choose random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original Text:\\n {random_sentence}\\n\\n Vectorized Version:\")\n",
        "text_vectorizer([random_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "cc576a98-2958-483f-906a-41f552964810",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc576a98-2958-483f-906a-41f552964810",
        "outputId": "c17ba50e-e913-49f1-da91-94f3341a9a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ],
      "source": [
        "# find the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in training data\n",
        "top_5_words = words_in_vocab[:5] # get most common words\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de28dd8-9ebd-470e-8596-b0b4cb630b11",
      "metadata": {
        "id": "4de28dd8-9ebd-470e-8596-b0b4cb630b11"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make the embedding I will be using the TensorFlow Embedding Layer via `tf.keras.layers.Embedding`\n",
        "\n",
        "Params for Embedding Layer:\n",
        "* `input_dim` - Size of the vocabulary\n",
        "* `output_dim` - the size of the output embedding vector, the vector representation of the word will be this many float values long\n",
        "* `input_length` - length of sequences being passed to the embedding layer (set to 15 earlier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1aeb2d80-03ea-4350-b3ca-bb95a6d38bee",
      "metadata": {
        "id": "1aeb2d80-03ea-4350-b3ca-bb95a6d38bee"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length) # how long is each input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "466745fd-a8a9-4108-a3d0-9fa262bebe4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "466745fd-a8a9-4108-a3d0-9fa262bebe4c",
        "outputId": "f84106dc-98a0-4ebb-b71f-ffa227482a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " Thought it was a drought @_ASHJ? http://t.co/V4Br5gjMIY\n",
            "\n",
            "Embedded Version:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 2.5300417e-02, -3.9192475e-02, -4.9914766e-02, ...,\n",
              "         -3.2820329e-03, -4.5645025e-02, -2.0805229e-02],\n",
              "        [-2.3712862e-02,  1.3817597e-02,  3.1843308e-02, ...,\n",
              "         -2.0293951e-02,  3.3630971e-02,  2.4327587e-02],\n",
              "        [ 3.0481521e-02, -1.5789628e-02,  1.3799038e-02, ...,\n",
              "          3.5035942e-02, -4.2891968e-02, -5.2489340e-05],\n",
              "        ...,\n",
              "        [ 4.4674125e-02, -1.0418735e-02,  1.1442997e-02, ...,\n",
              "         -1.2409963e-02,  2.1032784e-02, -2.3992373e-02],\n",
              "        [ 4.4674125e-02, -1.0418735e-02,  1.1442997e-02, ...,\n",
              "         -1.2409963e-02,  2.1032784e-02, -2.3992373e-02],\n",
              "        [ 4.4674125e-02, -1.0418735e-02,  1.1442997e-02, ...,\n",
              "         -1.2409963e-02,  2.1032784e-02, -2.3992373e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# get random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original Text:\\n {random_sentence}\\n\\nEmbedded Version:\\n\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3321a4a1-0214-4e12-9473-f4bb18dbf715",
      "metadata": {
        "id": "3321a4a1-0214-4e12-9473-f4bb18dbf715"
      },
      "source": [
        "> 3 dimensions: 1 sequence, 15 tokens, 128 float values representing each token (word)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "294f4f8e-9b9c-4b8d-9ac8-807d1c5bed47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "294f4f8e-9b9c-4b8d-9ac8-807d1c5bed47",
        "outputId": "7a4e86a5-2ce2-4b1f-d7cd-f28451ac0caa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.02530042, -0.03919248, -0.04991477, -0.0089213 ,  0.04938241,\n",
              "         0.03212552, -0.01810931, -0.00484425, -0.02819156, -0.04794249,\n",
              "         0.04864398,  0.04013126, -0.04621777,  0.0240005 , -0.02970241,\n",
              "         0.03287921, -0.0494904 ,  0.04103797,  0.02669685, -0.02472763,\n",
              "         0.02368298,  0.04176605, -0.02795473, -0.04107437,  0.04934213,\n",
              "        -0.00425757, -0.02122968, -0.04448226,  0.03352305,  0.04436103,\n",
              "         0.0175509 ,  0.02851078,  0.04015655,  0.03729348, -0.0422639 ,\n",
              "        -0.04793688, -0.0223188 , -0.01676657,  0.04375928, -0.00388291,\n",
              "         0.02829948, -0.01606231,  0.0344619 ,  0.01342   , -0.03395762,\n",
              "        -0.04328334,  0.01078639, -0.03919299, -0.02231017,  0.04931773,\n",
              "         0.00453148, -0.02528858,  0.01481814,  0.03890653, -0.00025135,\n",
              "        -0.04703635,  0.04472348, -0.01455658, -0.0395655 ,  0.03891492,\n",
              "         0.04246986,  0.01096515, -0.04459429,  0.0178494 ,  0.02297791,\n",
              "        -0.0238012 , -0.01536297,  0.00054568, -0.00642978, -0.01407607,\n",
              "         0.029773  , -0.0052245 , -0.00535771, -0.03424808, -0.01104895,\n",
              "        -0.03161509,  0.03248206,  0.0015521 ,  0.01600191,  0.03020838,\n",
              "         0.00918693, -0.00662214, -0.01726009, -0.00868813, -0.04187163,\n",
              "        -0.00450944, -0.00832292, -0.01616959, -0.01123047,  0.04408631,\n",
              "         0.00175809, -0.04330808,  0.00828331, -0.02422382, -0.03336622,\n",
              "        -0.04284338, -0.03356769, -0.04819135, -0.03393701,  0.00320609,\n",
              "        -0.02714661,  0.03250686,  0.02586308,  0.03599543,  0.01927383,\n",
              "        -0.02878864,  0.00074484,  0.02787409, -0.04426485, -0.0489561 ,\n",
              "         0.02108803, -0.009535  , -0.00712413,  0.03284291, -0.00579233,\n",
              "        -0.00745342,  0.03668943,  0.04131576, -0.03500792, -0.03038242,\n",
              "         0.01732085,  0.03004699, -0.0188895 ,  0.02465701, -0.00848621,\n",
              "        -0.00328203, -0.04564502, -0.02080523], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Thought it was a drought @_ASHJ? http://t.co/V4Br5gjMIY')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# check out single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape,  random_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54571f63-c920-4ec0-bcae-15f2ae53f302",
      "metadata": {
        "id": "54571f63-c920-4ec0-bcae-15f2ae53f302"
      },
      "source": [
        "## modeling a text dataset (series of experiments)\n",
        "\n",
        "The modeling experiements will be:\n",
        "\n",
        "* Model 0: Naive Bays (baseline, sci-kit learn)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM Model (RNN)\n",
        "* Model 3: GRU Model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of the training data (to explore a data constrained scenario)\n",
        "\n",
        "Steps for modeling:\n",
        "1. Create a model\n",
        "2. Build a model\n",
        "3. Fit a model\n",
        "4. Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e48b2888-efe6-4779-b39c-3b1e48473b70",
      "metadata": {
        "id": "e48b2888-efe6-4779-b39c-3b1e48473b70"
      },
      "source": [
        "### Model 0: Baseline model\n",
        "\n",
        "To build the baseline, I'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> It seems commonplace to use non-DL machine learning models to establish a baseline only moving on to Deep Learning when ready to improve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3d75fc9c-41fc-48a3-938d-32b48505fc0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d75fc9c-41fc-48a3-938d-32b48505fc0a",
        "outputId": "88835ba8-20f7-44ae-aca3-dd94c82e07c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create tokenization and modeling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "bf8a78ba-2844-4927-a79b-18d40a0c2211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf8a78ba-2844-4927-a79b-18d40a0c2211",
        "outputId": "dcf062ce-4f38-48d5-f5ce-ed48f27fe1ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline achieves accuracy of: 79.27%\n"
          ]
        }
      ],
      "source": [
        "# evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Baseline achieves accuracy of: {baseline_score * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f1677fe6-ba5e-4ea7-8ce6-2b282deb029f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1677fe6-ba5e-4ea7-8ce6-2b282deb029f",
        "outputId": "d31ff5b9-87a0-43bf-bf23-d0d1135bb407"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Make prediction\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df5f072-7eae-4996-8273-46939f5420f3",
      "metadata": {
        "id": "2df5f072-7eae-4996-8273-46939f5420f3"
      },
      "source": [
        "### creating an evaluation function for model experiments\n",
        "\n",
        "Using the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0dd2c5a6-7efe-4fcd-8095-4b995fc15b5d",
      "metadata": {
        "id": "0dd2c5a6-7efe-4fcd-8095-4b995fc15b5d"
      },
      "outputs": [],
      "source": [
        "# Fucntion to evaluate: accuracy, precision, recall, F1-Score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_preds):\n",
        "    \"\"\"\n",
        "    Calculates model accuracy, precision, recall, and f1 score for a binary classification model.\n",
        "    \"\"\"\n",
        "    # calculate model accuracy\n",
        "    model_accuracy = accuracy_score(y_true, y_preds) * 100\n",
        "    # calculate model precision, recall, and f1-score 'weighted' average (supports label imbalance)\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_preds, average=\"weighted\")\n",
        "    model_results = {\"accuracy\": model_accuracy,\n",
        "                     \"precision\": model_precision,\n",
        "                     \"recall\": model_recall,\n",
        "                     \"f1\": model_f1}\n",
        "    \n",
        "    return model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "3bbf22fb-1e3f-4adb-9301-54f0fa825e66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bbf22fb-1e3f-4adb-9301-54f0fa825e66",
        "outputId": "3c96973b-d7ab-4efd-b075-007daa4b2a51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_preds=baseline_preds)\n",
        "\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9dc54d6-4aad-459f-b775-c52601299d1a",
      "metadata": {
        "id": "e9dc54d6-4aad-459f-b775-c52601299d1a"
      },
      "source": [
        "## model 1: a simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2e2cccf8-21d9-4988-96c7-14d73c6e8d26",
      "metadata": {
        "id": "2e2cccf8-21d9-4988-96c7-14d73c6e8d26"
      },
      "outputs": [],
      "source": [
        "# create a tensorboard callback (create new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e4e8ce59-3659-4973-84e9-08557d237a86",
      "metadata": {
        "id": "e4e8ce59-3659-4973-84e9-08557d237a86"
      },
      "outputs": [],
      "source": [
        "# build a model with the funcitonal api\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # one dimensional and of type string only\n",
        "x = text_vectorizer(inputs) # turn input text into numbers\n",
        "x = embedding(x) # create an embedding of the numeric inputs\n",
        "x = layers.GlobalAveragePooling1D(name=\"global_avg_pool_layer\")(x) # condence feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, binary outputs = 1 and activation of sigmoid\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "6cff7614-1522-4fbb-9411-5286b4d0bc06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cff7614-1522-4fbb-9411-5286b4d0bc06",
        "outputId": "ef16ebe0-4b1b-4dfc-b069-ab03865d0250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_avg_pool_layer (Glob  (None, 128)              0         \n",
            " alAveragePooling1D)                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "beb21453-3a36-4069-aca2-8cd5aed932bf",
      "metadata": {
        "id": "beb21453-3a36-4069-aca2-8cd5aed932bf"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "13deda3b-f28c-4c82-8cdd-f0c5bd45cec7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13deda3b-f28c-4c82-8cdd-f0c5bd45cec7",
        "outputId": "ccce3666-fa1a-4e11-de4d-8a1ed7d06960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230127-171751\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 5ms/step - loss: 0.6108 - accuracy: 0.6981 - val_loss: 0.5371 - val_accuracy: 0.7480\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.4416 - accuracy: 0.8178 - val_loss: 0.4702 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.3478 - accuracy: 0.8603 - val_loss: 0.4612 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2850 - accuracy: 0.8897 - val_loss: 0.4637 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2385 - accuracy: 0.9124 - val_loss: 0.4785 - val_accuracy: 0.7900\n"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "model_1_history = model_1.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                    experiment_name=\"model_1_dense\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e3ef3593-cb8f-453a-8879-6790ebed9321",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3ef3593-cb8f-453a-8879-6790ebed9321",
        "outputId": "d39c2c5e-9590-493d-9712-4e929bc8a54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47853755950927734, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# check results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "fbae942a-8714-4975-9af0-c6be6449de7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbae942a-8714-4975-9af0-c6be6449de7b",
        "outputId": "5955cd5b-72e0-4910-ee2e-8a33b5f12898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# make predictions\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "95fa2a85-b739-4186-882b-098d9bc903ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95fa2a85-b739-4186-882b-098d9bc903ca",
        "outputId": "e1c64b72-5af7-4834-9334-b71c4d03544b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4081801 ],\n",
              "       [0.79052293],\n",
              "       [0.99770075],\n",
              "       [0.11320852],\n",
              "       [0.11179869]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# check out the probability matrix\n",
        "model_1_pred_probs[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cdbbfc5f-cf12-469d-a531-0cd3d1a7f155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdbbfc5f-cf12-469d-a531-0cd3d1a7f155",
        "outputId": "53cb293f-4d59-4c0a-b848-5467c49a5bf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# convert model prediction probabilities to model format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5d75e596-ea94-4643-87ea-ea2534ea5713",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d75e596-ea94-4643-87ea-ea2534ea5713",
        "outputId": "9f01b503-a837-4efd-d5b2-f30ed73802b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'precision': 0.7946291128165941,\n",
              " 'recall': 0.7900262467191601,\n",
              " 'f1': 0.7872155322757017}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# calculate model_1 results\n",
        "model_1_results = calculate_results(val_labels,\n",
        "                                    model_1_preds)\n",
        "\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "5ec1e617-bc7f-4321-9cd6-10faa1a8b5e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ec1e617-bc7f-4321-9cd6-10faa1a8b5e4",
        "outputId": "94780e59-4a17-465f-e31f-73105d7f616c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# check all values of model_1 against baseline\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f05b022-f31d-4f89-95fd-6aecde0ff8de",
      "metadata": {
        "id": "5f05b022-f31d-4f89-95fd-6aecde0ff8de"
      },
      "source": [
        "> We see that only the F1 score resulted in a higher value over the baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93c51422-3e00-4401-8fe7-66cc5145ad5b",
      "metadata": {
        "id": "93c51422-3e00-4401-8fe7-66cc5145ad5b"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9c41e965-68e2-437a-bd75-c10de91b1c0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c41e965-68e2-437a-bd75-c10de91b1c0a",
        "outputId": "bf1f6cd8-5af9-4ee6-8397-67e5fd506b01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a179b282-a63f-47f4-8498-6056d93f08c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a179b282-a63f-47f4-8498-6056d93f08c6",
        "outputId": "eb94dafe-7ce2-4342-9f22-779e9fcadc2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_avg_pool_layer (Glob  (None, 128)              0         \n",
            " alAveragePooling1D)                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model 1 summary\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8f2bf443-1249-44f5-b65a-5a5644233d52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f2bf443-1249-44f5-b65a-5a5644233d52",
        "outputId": "f44b2b3d-914f-4310-e24e-e3aa8e336a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ],
      "source": [
        "# get the weight matrix of embedding layer (numerical representation of each token in our training data)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "print(embed_weights.shape) # same size as vocab and embedding_dim (output dim of our embedding layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "975db12a-5dcc-4e05-a952-415d7d78c070",
      "metadata": {
        "id": "975db12a-5dcc-4e05-a952-415d7d78c070"
      },
      "source": [
        "Tensorflow has a tool called projector: http://projector.tensorflow.org/\n",
        "\n",
        "Tensorflow embeddings documentation: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "a6b7a75f-dc81-446c-8474-683fe6fe0c19",
      "metadata": {
        "id": "a6b7a75f-dc81-446c-8474-683fe6fe0c19"
      },
      "outputs": [],
      "source": [
        "# create embedding files, this code is in embedding documentation\n",
        "import io\n",
        "\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b03cc445-eb56-48ff-9084-417eb01fb1c4",
      "metadata": {
        "id": "b03cc445-eb56-48ff-9084-417eb01fb1c4"
      },
      "source": [
        "> Manually downloaded the `metadata.tsv` and `vectors.tsv`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c54dc5c9-564e-47a0-adc1-61311a64582e",
      "metadata": {
        "id": "c54dc5c9-564e-47a0-adc1-61311a64582e"
      },
      "source": [
        "## Recurrent Neural Network\n",
        "\n",
        "RNN's are primarily used for sequence data.\n",
        "\n",
        "RNN's use the representation of a previous input for a later representation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de55fcbe-cce9-413b-84d2-6542381ee7b5",
      "metadata": {
        "id": "de55fcbe-cce9-413b-84d2-6542381ee7b5"
      },
      "source": [
        "## Model 2: LSTM\n",
        "\n",
        "LSTM = Long Short-Term Memory\n",
        "\n",
        "Architecture:\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNN/Dense) -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "d585105d-4709-4ba4-92a2-1d324ccf972d",
      "metadata": {
        "id": "d585105d-4709-4ba4-92a2-1d324ccf972d"
      },
      "outputs": [],
      "source": [
        "# This kernel is representing the shape incorrectly for LSTM and GRU, this modifies the expected shape of the data\n",
        "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
        "\n",
        "# create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.LSTM(units=64, return_sequences=True)(x) # when stacking RNN cells together, need to return_sequences\n",
        "x = layers.LSTM(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "133b1c11-ceaf-4241-91da-18e7dc73e34e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "133b1c11-ceaf-4241-91da-18e7dc73e34e",
        "outputId": "a6d8b388-ec58-46aa-d126-afe035a7b363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# get a summary of model_2\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "bea29cb7-4c11-4d3a-a7f8-cafe60f2a3a8",
      "metadata": {
        "id": "bea29cb7-4c11-4d3a-a7f8-cafe60f2a3a8"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "2d6d50b4-1314-4c22-b717-5ccfc9ab737f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d6d50b4-1314-4c22-b717-5ccfc9ab737f",
        "outputId": "415f2c3e-7558-4eec-c125-f7fb5ab30d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230127-171804\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 9ms/step - loss: 0.2250 - accuracy: 0.9175 - val_loss: 0.5097 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1591 - accuracy: 0.9404 - val_loss: 0.5726 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1274 - accuracy: 0.9508 - val_loss: 0.7478 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1062 - accuracy: 0.9602 - val_loss: 0.8423 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0871 - accuracy: 0.9679 - val_loss: 0.9823 - val_accuracy: 0.7717\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "c21c24a4-0553-4b3b-8df8-4ad2fba64604",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c21c24a4-0553-4b3b-8df8-4ad2fba64604",
        "outputId": "8760d675-238b-4a1e-8e3a-e6d8a9cbdf05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.01574585e-02],\n",
              "       [7.95881629e-01],\n",
              "       [9.99791801e-01],\n",
              "       [2.17962991e-02],\n",
              "       [5.28928649e-04],\n",
              "       [9.99382019e-01],\n",
              "       [9.47596908e-01],\n",
              "       [9.99875784e-01],\n",
              "       [9.99813259e-01],\n",
              "       [7.15352893e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "61618a2b-851c-4c59-96f3-db1402b3f2a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61618a2b-851c-4c59-96f3-db1402b3f2a7",
        "outputId": "f2ede684-f075-4fd8-a61b-d3701f620107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "4b575af2-ae20-4401-b6e8-6c17144a1616",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b575af2-ae20-4401-b6e8-6c17144a1616",
        "outputId": "3b439f91-6a5f-4f5f-ae4b-7dbda5b525c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'precision': 0.7726063176824562,\n",
              " 'recall': 0.7716535433070866,\n",
              " 'f1': 0.7699532001851459}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels, y_preds=model_2_preds)\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "7d6aa9f0-43d3-451d-b985-5f8f7dc40293",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d6aa9f0-43d3-451d-b985-5f8f7dc40293",
        "outputId": "919c8698-a3ec-4ca1-f0a7-ec1680adbf92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "869541e5-c982-42be-a10d-1c10cdaf3616",
      "metadata": {
        "id": "869541e5-c982-42be-a10d-1c10cdaf3616"
      },
      "outputs": [],
      "source": [
        "# Create a GRU model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs = layers.Dense(1, activation=\"tanh\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "aa4a23da-d48f-4b5b-abb3-c93b97e18f54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa4a23da-d48f-4b5b-abb3-c93b97e18f54",
        "outputId": "562ed426-c3dc-4d86-c80f-ca0a1a2f5468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# get model 3 summary\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "1c45a116-9e33-4c2a-8d5c-bda7e8dac288",
      "metadata": {
        "id": "1c45a116-9e33-4c2a-8d5c-bda7e8dac288"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "60f57d65-319c-41a0-a5ac-7711277a9a85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60f57d65-319c-41a0-a5ac-7711277a9a85",
        "outputId": "12d35d41-4c6c-4478-8494-6a21087a412e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230127-171817\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 8ms/step - loss: 0.4061 - accuracy: 0.8869 - val_loss: 1.6613 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1971 - accuracy: 0.9439 - val_loss: 0.9280 - val_accuracy: 0.7126\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.9603 - val_loss: 1.5556 - val_accuracy: 0.7782\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1246 - accuracy: 0.9721 - val_loss: 1.7122 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1210 - accuracy: 0.9759 - val_loss: 1.6663 - val_accuracy: 0.7730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1de16af250>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# fit model 3\n",
        "model_3.fit(train_sentences,\n",
        "            train_labels,\n",
        "            validation_data=(val_sentences, val_labels),\n",
        "            epochs=5,\n",
        "            callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                   \"model_2_LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "e2baa6ce-44ac-4613-964a-10f1c115a709",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2baa6ce-44ac-4613-964a-10f1c115a709",
        "outputId": "ef13ad29-ede0-4861-fd6a-3e3839615dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# make predictions with GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "3e4ebdb6-ddb6-48df-9010-f1c97cef9975",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e4ebdb6-ddb6-48df-9010-f1c97cef9975",
        "outputId": "132cd60a-57b8-482d-8389-28ccf6c6fe72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_3_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "b16c3cef-c63f-482a-8ab2-95d95f75fc4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b16c3cef-c63f-482a-8ab2-95d95f75fc4a",
        "outputId": "f3684fca-0955-4f0f-c006-391082a6530c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'precision': 0.7726063176824562,\n",
              " 'recall': 0.7716535433070866,\n",
              " 'f1': 0.7699532001851459}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, y_preds=model_3_preds)\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "f2744029-7ce3-48d8-9529-24fe9065955f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2744029-7ce3-48d8-9529-24fe9065955f",
        "outputId": "7d6006b1-dd34-4208-b008-c6a9d3d41df3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd4b3a18-76fa-4e4a-9945-799abf9cf3be",
      "metadata": {
        "id": "dd4b3a18-76fa-4e4a-9945-799abf9cf3be"
      },
      "source": [
        "### Model 4: Bidirectional RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "45d3eb00-c177-4829-8d0e-0187564a9c64",
      "metadata": {
        "id": "45d3eb00-c177-4829-8d0e-0187564a9c64"
      },
      "outputs": [],
      "source": [
        "# Create a bidirectional RNN\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "60e66455-33d1-4110-aecf-944f42a2ac90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60e66455-33d1-4110-aecf-944f42a2ac90",
        "outputId": "3a96f3e9-196a-4676-9a49-236b2f09e1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "83cc9a69-4c96-45c5-bb46-59519b6ae8f8",
      "metadata": {
        "id": "83cc9a69-4c96-45c5-bb46-59519b6ae8f8"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "f9a7b88f-f099-4937-8887-050e9a464549",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9a7b88f-f099-4937-8887-050e9a464549",
        "outputId": "9fb6c011-d40c-428e-decf-f1cf352c1e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230127-171830\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 11ms/step - loss: 0.1123 - accuracy: 0.9712 - val_loss: 0.7959 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0672 - accuracy: 0.9753 - val_loss: 0.9273 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0587 - accuracy: 0.9753 - val_loss: 0.9848 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0483 - accuracy: 0.9810 - val_loss: 1.2457 - val_accuracy: 0.7612\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0442 - accuracy: 0.9799 - val_loss: 1.1948 - val_accuracy: 0.7441\n"
          ]
        }
      ],
      "source": [
        "# fit data\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_4_bidirectional\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "959bab14-91d1-49c7-a053-664deed71b64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "959bab14-91d1-49c7-a053-664deed71b64",
        "outputId": "fa47dbca-8fdd-4b43-8b8b-a84067a55b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "model_4_pred_probs = model_4.predict(val_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "d630f067-80b5-4a37-9665-a5988dc811a5",
      "metadata": {
        "id": "d630f067-80b5-4a37-9665-a5988dc811a5"
      },
      "outputs": [],
      "source": [
        "# convert pred probs to pre labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "116fbbcb-794b-4888-a78a-fa8723b18d11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "116fbbcb-794b-4888-a78a-fa8723b18d11",
        "outputId": "f96c0f7f-8a36-4a1d-f083-e06fd33d656e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.40944881889764,\n",
              " 'precision': 0.7455720514146248,\n",
              " 'recall': 0.7440944881889764,\n",
              " 'f1': 0.7444631382052128}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Calculate the results of model_4\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_preds=model_4_preds)\n",
        "model_4_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074aa466-c192-425c-9304-ab0db765fdc8",
      "metadata": {
        "id": "074aa466-c192-425c-9304-ab0db765fdc8"
      },
      "source": [
        "## CNN for text and other types of sequences\n",
        "\n",
        "CNN's are typically for images, images are 2D. Text is 1D, `Conv1D` is what I'll be using\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c69155c-acd8-42db-a6d2-73fe288ce0c1",
      "metadata": {
        "id": "4c69155c-acd8-42db-a6d2-73fe288ce0c1"
      },
      "source": [
        "### Model 5: Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "e0a9a34a-cbcb-4bd5-bdd0-787056712e59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0a9a34a-cbcb-4bd5-bdd0-787056712e59",
        "outputId": "ae81e11a-c559-4434-c8c1-b5932d8a1fee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# Test out embedding layer, Conv1D layer and max pooling layer\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\")\n",
        "\n",
        "conv_1d_output = conv_1d(embedding_test)\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important feature / get feature with the highest value\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "3010a042-56f4-4eb0-8f2a-566b3e5179c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3010a042-56f4-4eb0-8f2a-566b3e5179c3",
        "outputId": "50dbf80e-9769-4b12-f5ed-8b3ef4259bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build conv1d model\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\", padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# compile\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# summary of model\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "6709872c-5f79-42b4-88c5-04f2548ca289",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6709872c-5f79-42b4-88c5-04f2548ca289",
        "outputId": "a22b5681-6bae-4acd-a005-28bb4e71382e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20230127-171847\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 6ms/step - loss: 0.1274 - accuracy: 0.9590 - val_loss: 0.8613 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0761 - accuracy: 0.9739 - val_loss: 1.0343 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 0.9766 - val_loss: 1.0314 - val_accuracy: 0.7638\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0584 - accuracy: 0.9772 - val_loss: 1.1571 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9780 - val_loss: 1.2099 - val_accuracy: 0.7585\n"
          ]
        }
      ],
      "source": [
        "# fit\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "71badc6e-1a45-4a91-8025-1910833e353b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71badc6e-1a45-4a91-8025-1910833e353b",
        "outputId": "17c78bc9-8818-4c8f-f342-765a742aa382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6183892e-01],\n",
              "       [9.3920058e-01],\n",
              "       [9.9985409e-01],\n",
              "       [5.6436278e-02],\n",
              "       [1.4730230e-07],\n",
              "       [9.9867284e-01],\n",
              "       [9.2865133e-01],\n",
              "       [9.9986887e-01],\n",
              "       [9.9999952e-01],\n",
              "       [6.9635040e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# make some predictions\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "b02bf169-f23f-4d12-ac6f-95fff1c09b68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b02bf169-f23f-4d12-ac6f-95fff1c09b68",
        "outputId": "e97c42ce-bc21-4688-f56f-8906a83d0a6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# convert model 5 pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "1d4ee3f2-9b0e-491a-a702-f60c5fc107ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d4ee3f2-9b0e-491a-a702-f60c5fc107ae",
        "outputId": "113b2c44-eb7e-45ac-e5ec-f3f261895c1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'precision': 0.7585993128505528,\n",
              " 'recall': 0.7585301837270341,\n",
              " 'f1': 0.7572040956354258}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# evaluate model 5\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_preds=model_5_preds)\n",
        "model_5_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "74e0a4c8-79fb-43af-8843-6e60c13548b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74e0a4c8-79fb-43af-8843-6e60c13548b5",
        "outputId": "db03e316-ff1a-412b-fc23-26111e1da85b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59dfe961-dd94-4315-8223-4627f51445b5",
      "metadata": {
        "id": "59dfe961-dd94-4315-8223-4627f51445b5"
      },
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "41038ea5-719e-4e06-b5b7-7ac5299face8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41038ea5-719e-4e06-b5b7-7ac5299face8",
        "outputId": "2cf3cee2-f8f5-473b-fe75-24cdc191936a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157028  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680984  0.05589836 -0.0106873  -0.00597291  0.00639323 -0.01819518\n",
            "  0.00030813  0.09105888  0.05874644 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865347 -0.04209306  0.02678981  0.03011006  0.00321069\n",
            " -0.00337973 -0.04787357  0.0226672  -0.00985925 -0.04063613 -0.01292092\n",
            " -0.04666384  0.05630299 -0.03949255  0.00517686  0.02495829 -0.0701444\n",
            "  0.02871508  0.04947684 -0.00633979 -0.08960192  0.02807118 -0.00808364\n",
            " -0.01360602  0.0599865  -0.10361787 -0.05195374  0.00232954 -0.02332531\n",
            " -0.03758105  0.03327728], shape=(50,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call universal sentence encoder on a sentence, it converts it to a number\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNSscE1YRBtj",
        "outputId": "a3d69385-c584-4101-eea7-71bb83b4c2b0"
      },
      "id": "VNSscE1YRBtj",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras layer using teh USE pretrained layer from TF Hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # due to variable input length for pretrained model, this is blank for variable acceptance\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "metadata": {
        "id": "IIDdll6-TtQQ"
      },
      "id": "IIDdll6-TtQQ",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using sequential api\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")"
      ],
      "metadata": {
        "id": "RbfwXN56WA6b"
      },
      "id": "RbfwXN56WA6b",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "czxeo3D-WVoe"
      },
      "id": "czxeo3D-WVoe",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjMVzlovWjLb",
        "outputId": "0b6b5a88-d6f2-4ab6-d2f5-213c7243ca28"
      },
      "id": "PjMVzlovWjLb",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train a classifier on top of pretrained embedding\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                   \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_fPrQ3PWkJy",
        "outputId": "82d536b8-0f00-4347-ac04-c19d588daedd"
      },
      "id": "y_fPrQ3PWkJy",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20230127-181521\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 14ms/step - loss: 0.5054 - accuracy: 0.7815 - val_loss: 0.4471 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4139 - accuracy: 0.8159 - val_loss: 0.4347 - val_accuracy: 0.8150\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3995 - accuracy: 0.8260 - val_loss: 0.4273 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3909 - accuracy: 0.8243 - val_loss: 0.4256 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3829 - accuracy: 0.8297 - val_loss: 0.4264 - val_accuracy: 0.8150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# made predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEshemJ6bX6V",
        "outputId": "b2b5f8fa-617f-43fc-d999-d358eeabaaad"
      },
      "id": "QEshemJ6bX6V",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14827354],\n",
              "       [0.7456085 ],\n",
              "       [0.9910029 ],\n",
              "       [0.19793382],\n",
              "       [0.7106697 ],\n",
              "       [0.7466158 ],\n",
              "       [0.9827565 ],\n",
              "       [0.98062027],\n",
              "       [0.9385668 ],\n",
              "       [0.07584741]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert prediciton probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MSaO7F5btuU",
        "outputId": "c16c2a70-c393-4156-a885-6a44c095fb0e"
      },
      "id": "4MSaO7F5btuU",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate model_6 performance results\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_preds=model_6_preds)\n",
        "\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfkKVOTzb2tO",
        "outputId": "83886ed1-e13b-4e6d-82ee-915e29569dd8"
      },
      "id": "RfkKVOTzb2tO",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.49606299212599,\n",
              " 'precision': 0.8182618558292442,\n",
              " 'recall': 0.8149606299212598,\n",
              " 'f1': 0.8131230163581015}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE1Tl6dQcDi0",
        "outputId": "4aed767b-4db4-4d9e-9ec4-0d3aba8e797c"
      },
      "id": "nE1Tl6dQcDi0",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: TF Hub USE except 10% of training data\n",
        "\n",
        "Transfer learning helps when dataset is small. Replicate `model_6` except with smaller dataset.\n",
        "\n",
        "Creating the same model as `model_6` using the `tf.keras.models.clone_model()` method. The `clone_model()` method resets all weights for the layers of the model."
      ],
      "metadata": {
        "id": "4IbwDZjBcGzu"
      },
      "id": "4IbwDZjBcGzu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE:** This created a data leakage.\n",
        "\n",
        "(#) Create subsets of 10% of the training data\n",
        "```\n",
        "train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "````"
      ],
      "metadata": {
        "id": "2wzoPZ6JdNxw"
      },
      "id": "2wzoPZ6JdNxw"
    },
    {
      "cell_type": "code",
      "source": [
        "# created better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "print(train_10_percent_split)\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "print(len(train_sentences_10_percent))\n",
        "print(len(train_labels_10_percent))\n",
        "train_labels_10_percent.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmA9wwxth0tW",
        "outputId": "a4f31ed9-3163-4023-fd9f-91ecaf42f93a"
      },
      "id": "hmA9wwxth0tW",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "685\n",
            "685\n",
            "685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the distribution\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtRIyb8DjqSz",
        "outputId": "546bdea5-613d-49f9-9f59-477755a3b982"
      },
      "id": "TtRIyb8DjqSz",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The distributions are similar so we can proceed"
      ],
      "metadata": {
        "id": "aQctZzzdd94p"
      },
      "id": "aQctZzzdd94p"
    },
    {
      "cell_type": "code",
      "source": [
        "# build model \n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# get summary\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8odXpc0EeDo2",
        "outputId": "4c4d2a90-81e9-49cc-ab9e-e8a37b03aaa2"
      },
      "id": "8odXpc0EeDo2",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model to the 10% training data\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hitZytZe5ip",
        "outputId": "8a3fdd18-1cf4-4c1e-a99d-dca3af28b5a2"
      },
      "id": "_hitZytZe5ip",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20230127-185130\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 44ms/step - loss: 0.6723 - accuracy: 0.6745 - val_loss: 0.6511 - val_accuracy: 0.7192\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.6072 - accuracy: 0.7942 - val_loss: 0.5977 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.5374 - accuracy: 0.8058 - val_loss: 0.5439 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.4749 - accuracy: 0.8219 - val_loss: 0.5094 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.4316 - accuracy: 0.8307 - val_loss: 0.4931 - val_accuracy: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions for model trained on 10 percent of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn_9yTLHfeBh",
        "outputId": "7e6db1ba-3a5d-4595-b14b-2487113374fb"
      },
      "id": "Yn_9yTLHfeBh",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.224515  ],\n",
              "       [0.60046035],\n",
              "       [0.8981206 ],\n",
              "       [0.3633685 ],\n",
              "       [0.52927065],\n",
              "       [0.6944396 ],\n",
              "       [0.8668613 ],\n",
              "       [0.79560757],\n",
              "       [0.8116021 ],\n",
              "       [0.16821048]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrSpCagff1LZ",
        "outputId": "93e05fc1-495d-4d51-fcfd-170bcbe05619"
      },
      "id": "ZrSpCagff1LZ",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model 7\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_preds=model_7_preds)\n",
        "\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7qxSb2Gf7MD",
        "outputId": "471a57d3-75a2-4f8a-acbb-e16f05211050"
      },
      "id": "l7qxSb2Gf7MD",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'precision': 0.7774694686899193,\n",
              " 'recall': 0.7755905511811023,\n",
              " 'f1': 0.7734917819402004}"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX1v_nW0gCm5",
        "outputId": "dad65a9d-1df0-4358-8017-89c5c155928a"
      },
      "id": "aX1v_nW0gCm5",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.49606299212599,\n",
              " 'precision': 0.8182618558292442,\n",
              " 'recall': 0.8149606299212598,\n",
              " 'f1': 0.8131230163581015}"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The speed/score tradeoff"
      ],
      "metadata": {
        "id": "eUoW51eVgMhJ"
      },
      "id": "eUoW51eVgMhJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function to test the time of inference\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples)\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time - start_time # total time\n",
        "\n",
        "  time_per_pred = total_time / len(samples)\n",
        "\n",
        "  return total_time, time_per_pred"
      ],
      "metadata": {
        "id": "gCxRuVTck7h-"
      },
      "id": "gCxRuVTck7h-",
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate TF Hub Sentence Encover time per pred\n",
        "model_6_total_pred_timer, model_6_time_per_pred = pred_timer(model=model_6,\n",
        "                                                            samples=val_sentences)\n",
        "\n",
        "model_6_total_pred_timer, model_6_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRQbsXsPlrYP",
        "outputId": "73324f77-2231-4f64-c78d-59bcb9d18c53"
      },
      "id": "XRQbsXsPlrYP",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.346941859999788, 0.00045530427821494486)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate baseline time per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UrR28MXl-jY",
        "outputId": "09531655-5997-489a-fc57-ba459957f4ce"
      },
      "id": "5UrR28MXl-jY",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.06488025399994513, 8.51446902886419e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jIEMSlLCmRDS"
      },
      "id": "jIEMSlLCmRDS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow2_p310",
      "language": "python",
      "name": "conda_tensorflow2_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}